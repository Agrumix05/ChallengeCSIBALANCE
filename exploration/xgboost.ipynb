{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6cda263",
   "metadata": {},
   "source": [
    "Ogni riga = 24h consecutive\n",
    "\n",
    "Le time series sono ordinate cronologicamente\n",
    "\n",
    "Il sonno è alla fine della TS\n",
    "\n",
    "sleep_sleepTimeSeconds è affidabile\n",
    "\n",
    "-1 / -2 / None = missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20aadd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly\n",
    "from pathlib import Path\n",
    "import re\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "base = Path('./filtered_data/')\n",
    "\n",
    "groups_dfs = {}\n",
    "\n",
    "for csv_path in sorted(base.glob('group*/*.csv')):\n",
    "    group = csv_path.parent.name\n",
    "    m = re.search(r'dataset_user_(\\d+)_train\\.csv', csv_path.name)\n",
    "    if not m:\n",
    "        continue\n",
    "    user_id = int(m.group(1))\n",
    "    df = pd.read_csv(csv_path)\n",
    "    groups_dfs.setdefault(group, {})[user_id] = df\n",
    "\n",
    "base_test = Path('../data/')\n",
    "test_df= pd.read_csv(base_test / 'test.csv', sep=';')\n",
    "\n",
    "def convert_timeseries_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    def try_parse_list(x):\n",
    "        if isinstance(x, str) and x.strip().startswith('[') and x.strip().endswith(']'):\n",
    "            try:\n",
    "                return ast.literal_eval(x)\n",
    "            except (ValueError, SyntaxError):\n",
    "                return x\n",
    "        return x\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(try_parse_list)\n",
    "\n",
    "    return df\n",
    "for group, users in groups_dfs.items():\n",
    "    for user_id, df in users.items():\n",
    "        groups_dfs[group][user_id] = convert_timeseries_columns(df)\n",
    "\n",
    "# do the same for test_df\n",
    "test_df = convert_timeseries_columns(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39d759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def clean_ts(ts):\n",
    "    if not isinstance(ts, list):\n",
    "        return [np.nan]\n",
    "    return [np.nan if (x is None or x < 0) else x for x in ts]\n",
    "\n",
    "for group, users in groups_dfs.items():\n",
    "    for user_id, df in users.items():\n",
    "        for col in df.columns:\n",
    "            if isinstance(df[col].iloc[0], list):\n",
    "                df[col] = df[col].apply(clean_ts)\n",
    "        groups_dfs[group][user_id] = df\n",
    "\n",
    "# do the same for test_df\n",
    "for col in test_df.columns:\n",
    "    if isinstance(test_df[col].iloc[0], list):\n",
    "        test_df[col] = test_df[col].apply(clean_ts)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9f5fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_sampling(row, ts_col=\"hr_time_series\"):\n",
    "    ts = row[ts_col]\n",
    "\n",
    "    if ts is None or len(ts) < 10:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    T = len(ts)\n",
    "    dt_hours = 24.0 / T\n",
    "\n",
    "    sleep_sec = row.get(\"sleep_sleepTimeSeconds\", np.nan)\n",
    "    if np.isnan(sleep_sec):\n",
    "        return dt_hours, np.nan\n",
    "\n",
    "    sleep_hours = sleep_sec / 3600.0\n",
    "    N_sleep = int(sleep_hours / dt_hours)\n",
    "\n",
    "    # clamp di sicurezza\n",
    "    N_sleep = max(0, min(N_sleep, T))\n",
    "\n",
    "    return dt_hours, N_sleep\n",
    "for group, users in groups_dfs.items():\n",
    "    for user_id, df in users.items():\n",
    "\n",
    "        dt_list = []\n",
    "        n_sleep_list = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            dt, n_sleep = estimate_sampling(row)\n",
    "            dt_list.append(dt)\n",
    "            n_sleep_list.append(n_sleep)\n",
    "\n",
    "        df[\"dt_hours\"] = dt_list\n",
    "        df[\"N_sleep\"] = n_sleep_list\n",
    "\n",
    "        groups_dfs[group][user_id] = df\n",
    "\n",
    "# do the same for test_df\n",
    "dt_list = []\n",
    "n_sleep_list = []\n",
    "for _, row in test_df.iterrows():\n",
    "    dt, n_sleep = estimate_sampling(row)\n",
    "    dt_list.append(dt)\n",
    "    n_sleep_list.append(n_sleep)\n",
    "test_df[\"dt_hours\"] = dt_list\n",
    "test_df[\"N_sleep\"] = n_sleep_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccf45004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2410/2836321184.py:3: RuntimeWarning: Mean of empty slice\n",
      "  \"mean\": np.nanmean(x),\n",
      "/home/agrume/Desktop/projects/prj4CSI/venv/lib/python3.13/site-packages/numpy/lib/_nanfunctions_impl.py:2015: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/tmp/ipykernel_2410/2836321184.py:5: RuntimeWarning: All-NaN slice encountered\n",
      "  \"min\": np.nanmin(x),\n",
      "/tmp/ipykernel_2410/2836321184.py:6: RuntimeWarning: All-NaN slice encountered\n",
      "  \"max\": np.nanmax(x),\n"
     ]
    }
   ],
   "source": [
    "def ts_features(x):\n",
    "    return {\n",
    "        \"mean\": np.nanmean(x),\n",
    "        \"std\": np.nanstd(x),\n",
    "        \"min\": np.nanmin(x),\n",
    "        \"max\": np.nanmax(x),\n",
    "        \"missing_pct\": np.mean(np.isnan(x)),\n",
    "    }\n",
    "\n",
    "for group, users in groups_dfs.items():\n",
    "    for user_id, df in users.items():\n",
    "\n",
    "        feature_dicts = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            features = {}\n",
    "\n",
    "            for col in df.columns:\n",
    "                if isinstance(row[col], list):\n",
    "                    ts = np.array(row[col])\n",
    "                    N = len(ts)\n",
    "\n",
    "                    # --- TRY / EXCEPT QUI ---\n",
    "                    try:\n",
    "                        N_sleep_i = int(row[\"N_sleep\"])\n",
    "                    except (TypeError, ValueError):\n",
    "                        N_sleep_i = None\n",
    "\n",
    "                    if N_sleep_i is None or N_sleep_i <= 0 or N_sleep_i >= N:\n",
    "                        feat = ts_features(ts)\n",
    "                        features.update(\n",
    "                            {f\"{col}_all_{k}\": v for k, v in feat.items()}\n",
    "                        )\n",
    "                    else:\n",
    "                        day_indices = np.arange(0, N - N_sleep_i, dtype=int)\n",
    "                        night_indices = np.arange(N - N_sleep_i, N, dtype=int)\n",
    "\n",
    "                        ts_day = ts[day_indices]\n",
    "                        ts_night = ts[night_indices]\n",
    "\n",
    "                        feat_day = ts_features(ts_day)\n",
    "                        feat_night = ts_features(ts_night)\n",
    "\n",
    "                        features.update(\n",
    "                            {f\"{col}_day_{k}\": v for k, v in feat_day.items()}\n",
    "                        )\n",
    "                        features.update(\n",
    "                            {f\"{col}_night_{k}\": v for k, v in feat_night.items()}\n",
    "                        )\n",
    "\n",
    "            feature_dicts.append(features)\n",
    "\n",
    "        df_features = pd.DataFrame(feature_dicts)\n",
    "\n",
    "        df_final = pd.concat(\n",
    "            [df.reset_index(drop=True), df_features.reset_index(drop=True)],\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        groups_dfs[group][user_id] = df_final\n",
    "\n",
    "\n",
    "\n",
    "# do the same for test_df\n",
    "feature_dicts = []\n",
    "for _, row in test_df.iterrows():\n",
    "    features = {}\n",
    "\n",
    "    for col in test_df.columns:\n",
    "        if isinstance(row[col], list):\n",
    "            ts = np.array(row[col])\n",
    "            N = len(ts)\n",
    "\n",
    "            # --- TRY / EXCEPT QUI ---\n",
    "            try:\n",
    "                N_sleep_i = int(row[\"N_sleep\"])\n",
    "            except (TypeError, ValueError):\n",
    "                N_sleep_i = None\n",
    "\n",
    "            if N_sleep_i is None or N_sleep_i <= 0 or N_sleep_i >= N:\n",
    "                feat = ts_features(ts)\n",
    "                features.update(\n",
    "                    {f\"{col}_all_{k}\": v for k, v in feat.items()}\n",
    "                )\n",
    "            else:\n",
    "                day_indices = np.arange(0, N - N_sleep_i, dtype=int)\n",
    "                night_indices = np.arange(N - N_sleep_i, N, dtype=int)\n",
    "\n",
    "                ts_day = ts[day_indices]\n",
    "                ts_night = ts[night_indices]\n",
    "\n",
    "                feat_day = ts_features(ts_day)\n",
    "                feat_night = ts_features(ts_night)\n",
    "\n",
    "                features.update(\n",
    "                    {f\"{col}_day_{k}\": v for k, v in feat_day.items()}\n",
    "                )\n",
    "                features.update(\n",
    "                    {f\"{col}_night_{k}\": v for k, v in feat_night.items()}\n",
    "                )\n",
    "\n",
    "    feature_dicts.append(features)\n",
    "test_df_features = pd.DataFrame(feature_dicts)\n",
    "test_df = pd.concat(\n",
    "    [test_df.reset_index(drop=True), test_df_features.reset_index(drop=True)],\n",
    "    axis=1,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3298fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, users in groups_dfs.items():\n",
    "    for user_id, df in users.items():\n",
    "        df['deep_sleep_pct'] = np.nan\n",
    "        df['rem_sleep_pct'] = np.nan\n",
    "        df['light_sleep_pct'] = np.nan\n",
    "        df['awake_sleep_pct'] = np.nan\n",
    "        df['sleep_efficiency'] = np.nan\n",
    "        for row_idx, row in df.iterrows():\n",
    "            sleep_deepSleepSeconds = row.get(\"sleep_deepSleepSeconds\", np.nan)\n",
    "            sleep_lightSleepSeconds = row.get(\"sleep_lightSleepSeconds\", np.nan)\n",
    "            sleep_remSleepSeconds = row.get(\"sleep_remSleepSeconds\", np.nan)\n",
    "            sleep_timeSeconds = row.get(\"sleep_sleepTimeSeconds\", np.nan)\n",
    "            sleep_awakeTimeSeconds = row.get(\"sleep_awakeSleepSeconds\", np.nan)\n",
    "\n",
    "            deep_pct = sleep_deepSleepSeconds / sleep_timeSeconds \n",
    "            rem_pct = sleep_remSleepSeconds / sleep_timeSeconds\n",
    "            light_pct = sleep_lightSleepSeconds / sleep_timeSeconds\n",
    "            awake_pct = sleep_awakeTimeSeconds / sleep_timeSeconds\n",
    "            sleep_efficiency = sleep_timeSeconds / (sleep_timeSeconds + sleep_awakeTimeSeconds)\n",
    "            df.at[row_idx, 'deep_sleep_pct'] = deep_pct\n",
    "            df.at[row_idx, 'rem_sleep_pct'] = rem_pct\n",
    "            df.at[row_idx, 'light_sleep_pct'] = light_pct\n",
    "            df.at[row_idx, 'awake_sleep_pct'] = awake_pct\n",
    "            df.at[row_idx, 'sleep_efficiency'] = sleep_efficiency\n",
    "        groups_dfs[group][user_id] = df\n",
    "\n",
    "# do the same for test_df\n",
    "test_df['deep_sleep_pct'] = np.nan\n",
    "test_df['rem_sleep_pct'] = np.nan\n",
    "test_df['light_sleep_pct'] = np.nan\n",
    "test_df['awake_sleep_pct'] = np.nan\n",
    "test_df['sleep_efficiency'] = np.nan\n",
    "for row_idx, row in test_df.iterrows():\n",
    "    sleep_deepSleepSeconds = row.get(\"sleep_deepSleepSeconds\", np.nan)\n",
    "    sleep_lightSleepSeconds = row.get(\"sleep_lightSleepSeconds\", np.nan)\n",
    "    sleep_remSleepSeconds = row.get(\"sleep_remSleepSeconds\", np.nan)\n",
    "    sleep_timeSeconds = row.get(\"sleep_sleepTimeSeconds\", np.nan)\n",
    "    sleep_awakeTimeSeconds = row.get(\"sleep_awakeSleepSeconds\", np.nan)\n",
    "\n",
    "    deep_pct = sleep_deepSleepSeconds / sleep_timeSeconds \n",
    "    rem_pct = sleep_remSleepSeconds / sleep_timeSeconds\n",
    "    light_pct = sleep_lightSleepSeconds / sleep_timeSeconds\n",
    "    awake_pct = sleep_awakeTimeSeconds / sleep_timeSeconds\n",
    "    sleep_efficiency = sleep_timeSeconds / (sleep_timeSeconds + sleep_awakeTimeSeconds)\n",
    "    test_df.at[row_idx, 'deep_sleep_pct'] = deep_pct\n",
    "    test_df.at[row_idx, 'rem_sleep_pct'] = rem_pct\n",
    "    test_df.at[row_idx, 'light_sleep_pct'] = light_pct\n",
    "    test_df.at[row_idx, 'awake_sleep_pct'] = awake_pct\n",
    "    test_df.at[row_idx, 'sleep_efficiency'] = sleep_efficiency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "052c21d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    # sleep composition\n",
    "    \"deep_sleep_pct\",\n",
    "    \"rem_sleep_pct\",\n",
    "    \"light_sleep_pct\",\n",
    "    \"awake_sleep_pct\",\n",
    "    \"sleep_efficiency\",\n",
    "\n",
    "    # heart rate static\n",
    "    \"hr_restingHeartRate\",\n",
    "    \"hr_lastSevenDaysAvgRestingHeartRate\",\n",
    "    \"hr_maxHeartRate\",\n",
    "    \"hr_minHeartRate\",\n",
    "\n",
    "    # stress static\n",
    "    \"str_avgStressLevel\",\n",
    "    \"str_maxStressLevel\",\n",
    "\n",
    "    # activity\n",
    "    \"act_totalCalories\",\n",
    "    \"act_activeKilocalories\",\n",
    "    \"act_distance\",\n",
    "\n",
    "    # respiration static\n",
    "    \"resp_lowestRespirationValue\",\n",
    "    \"resp_highestRespirationValue\",\n",
    "    \"resp_avgSleepRespirationValue\",\n",
    "\n",
    "    # sampling info (utile!)\n",
    "    \"dt_hours\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8079ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "for group, users in groups_dfs.items():\n",
    "    for user_id, df in users.items():\n",
    "\n",
    "        df_model = df.copy()\n",
    "\n",
    "        # tieni solo righe valide\n",
    "        df_model = df_model.dropna(subset=[\"label\"])\n",
    "\n",
    "        X = df_model[FEATURES]\n",
    "        y = df_model[\"label\"]\n",
    "\n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "\n",
    "X_all = pd.concat(X_list, axis=0)\n",
    "y_all = pd.concat(y_list, axis=0)\n",
    "\n",
    "\n",
    "# x_list_test = test_df[FEATURES]\n",
    "# y_list_test = test_df[\"label\"]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4474a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = X_all.replace([np.inf, -np.inf], np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42eb9900",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = int(len(X_all) * 0.7)\n",
    "\n",
    "\n",
    "\n",
    "X_train = X_all.iloc[:split_idx]\n",
    "X_val   = X_all.iloc[split_idx:]\n",
    "\n",
    "\n",
    "\n",
    "y_train = y_all.iloc[:split_idx]\n",
    "y_val   = y_all.iloc[split_idx:]\n",
    "\n",
    "# X_train = X_all\n",
    "# y_train = y_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85d5a818",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XGBRegressor' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m      3\u001b[39m model = XGBRegressor(\n\u001b[32m      4\u001b[39m     n_estimators=\u001b[32m300\u001b[39m,\n\u001b[32m      5\u001b[39m     max_depth=\u001b[32m4\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     n_jobs=-\u001b[32m1\u001b[39m\n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Training semplice\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m(\n\u001b[32m     18\u001b[39m     X_train,\n\u001b[32m     19\u001b[39m     y_train\n\u001b[32m     20\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'XGBRegressor' object has no attribute 'train'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    \n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Training semplice\n",
    "model.train(\n",
    "    X_train,\n",
    "    y_train\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d4a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_val=x_list_test\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred = np.clip(y_pred, 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b97259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 10.613499641418457\n",
      "R2: -0.23205804824829102\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# y_val = y_list_test\n",
    "\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "r2  = r2_score(y_val, y_pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"R2:\", r2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
