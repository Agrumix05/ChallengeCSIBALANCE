{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "34a0048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "34aad8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                                                                               1\n",
      "day                                                                                      1\n",
      "label                                                                                   64\n",
      "hr_maxHeartRate                                                                        101\n",
      "hr_minHeartRate                                                                         45\n",
      "hr_restingHeartRate                                                                     47\n",
      "hr_lastSevenDaysAvgRestingHeartRate                                                     65\n",
      "hr_time_series                           [None, 80, 66, 55, 55, 52, 57, 60, 59, 51, 55,...\n",
      "resp_lowestRespirationValue                                                            6.0\n",
      "resp_highestRespirationValue                                                          19.0\n",
      "resp_avgWakingRespirationValue                                                        13.0\n",
      "resp_avgSleepRespirationValue                                                         12.0\n",
      "resp_avgTomorrowSleepRespirationValue                                                 12.0\n",
      "resp_time_series                         [-2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2.0, -2....\n",
      "str_maxStressLevel                                                                      88\n",
      "str_avgStressLevel                                                                      13\n",
      "stress_time_series                       [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...\n",
      "sleep_sleepTimeSeconds                                                             15000.0\n",
      "sleep_napTimeSeconds                                                                   0.0\n",
      "sleep_unmeasurableSleepSeconds                                                      5340.0\n",
      "sleep_deepSleepSeconds                                                              3240.0\n",
      "sleep_lightSleepSeconds                                                             9120.0\n",
      "sleep_remSleepSeconds                                                               2640.0\n",
      "sleep_awakeSleepSeconds                                                             1440.0\n",
      "act_totalCalories                                                                   2516.0\n",
      "act_activeKilocalories                                                                28.0\n",
      "act_distance                                                                           969\n",
      "act_activeTime                                                                         NaN\n",
      "sleep_averageRespirationValue                                                         12.0\n",
      "sleep_lowestRespirationValue                                                           9.0\n",
      "sleep_highestRespirationValue                                                         18.0\n",
      "sleep_awakeCount                                                                       NaN\n",
      "sleep_avgSleepStress                                                                   NaN\n",
      "sleep_avgHeartRate                                                                     NaN\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#read with pandas all the csv file in ./data/train/group0\n",
    "df0= pd.read_csv('../data/train/group0/dataset_user_0_train.csv', sep=';')\n",
    "df1= pd.read_csv('../data/train/group0/dataset_user_9_train.csv', sep=';')\n",
    "df18= pd.read_csv('../data/train/group0/dataset_user_18_train.csv', sep=';')\n",
    "df27= pd.read_csv('../data/train/group0/dataset_user_27_train.csv', sep=';')\n",
    "df36= pd.read_csv('../data/train/group0/dataset_user_36_train.csv', sep=';')\n",
    "\n",
    "\n",
    "#print of the single value of the firrst row of df0\n",
    "print(df18.iloc[1])\n",
    "\n",
    "\n",
    "df0=df18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "23908fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "base = Path('../data/train')\n",
    "\n",
    "groups_dfs = {}\n",
    "\n",
    "for csv_path in sorted(base.glob('group*/*.csv')):\n",
    "    group = csv_path.parent.name\n",
    "    m = re.search(r'dataset_user_(\\d+)_train\\.csv', csv_path.name)\n",
    "    if not m:\n",
    "        continue\n",
    "    user_id = int(m.group(1))\n",
    "    df = pd.read_csv(csv_path, sep=';')\n",
    "    groups_dfs.setdefault(group, {})[user_id] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a1a8249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: group0, User: 0, Rows: 27\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group0, User: 18, Rows: 25\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group0, User: 27, Rows: 4\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group0, User: 36, Rows: 22\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group0, User: 9, Rows: 29\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group1, User: 10, Rows: 26\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group1, User: 19, Rows: 13\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group1, User: 1, Rows: 22\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group1, User: 28, Rows: 9\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group1, User: 37, Rows: 24\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group2, User: 11, Rows: 20\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group2, User: 20, Rows: 13\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group2, User: 29, Rows: 25\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group2, User: 2, Rows: 14\n",
      "Columns with all NaN values: ['act_distance', 'act_activeTime']\n",
      "Group: group2, User: 38, Rows: 26\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group3, User: 12, Rows: 27\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group3, User: 21, Rows: 29\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group3, User: 30, Rows: 29\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group3, User: 39, Rows: 22\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group3, User: 3, Rows: 9\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group4, User: 13, Rows: 13\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group4, User: 22, Rows: 17\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group4, User: 31, Rows: 17\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group4, User: 40, Rows: 24\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group4, User: 4, Rows: 21\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group5, User: 14, Rows: 12\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group5, User: 23, Rows: 29\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group5, User: 32, Rows: 30\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group5, User: 41, Rows: 26\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group5, User: 5, Rows: 28\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group6, User: 15, Rows: 29\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group6, User: 24, Rows: 27\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group6, User: 33, Rows: 13\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group6, User: 42, Rows: 30\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group6, User: 6, Rows: 8\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group7, User: 16, Rows: 25\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group7, User: 25, Rows: 30\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group7, User: 34, Rows: 27\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group7, User: 43, Rows: 30\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group7, User: 7, Rows: 26\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group8, User: 17, Rows: 25\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group8, User: 26, Rows: 25\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group8, User: 35, Rows: 15\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group8, User: 44, Rows: 30\n",
      "Columns with all NaN values: ['act_activeTime']\n",
      "Group: group8, User: 8, Rows: 27\n",
      "Columns with all NaN values: ['act_activeTime']\n"
     ]
    }
   ],
   "source": [
    "#for each person in each group i want to know how many rows are in the dataframe\n",
    "total_users = 0\n",
    "nan_activity_count=0\n",
    "for group, users in groups_dfs.items():\n",
    "    total_users += 1\n",
    "    for user_id, df in users.items():\n",
    "        print(f'Group: {group}, User: {user_id}, Rows: {len(df)}')\n",
    "        # how many rows have Nan values and for wich columns\n",
    "        nan_counts = df.isna().sum()\n",
    "        # print(f'NaN counts:\\n{nan_counts[nan_counts > 0]}')\n",
    "        # if there are columns that are all NaN\n",
    "        all_nan_columns = nan_counts[nan_counts == len(df)].index.tolist()\n",
    "        if all_nan_columns:\n",
    "            print(f'Columns with all NaN values: {all_nan_columns}')\n",
    "            nan_activity_count+=1\n",
    "\n",
    "#all the users have the column act_activeTime empty so we can drop it\n",
    "for group, users in groups_dfs.items():\n",
    "    for user_id, df in users.items():\n",
    "        if 'act_activeTime' in df.columns:\n",
    "            df.drop(columns=['act_activeTime'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a46c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: group0, User: 0\n",
      "Group: group0, User: 18\n",
      "Group: group0, User: 27\n",
      "Group: group0, User: 36\n",
      "Group: group0, User: 9\n",
      "Group: group1, User: 10\n",
      "Group: group1, User: 19\n",
      "Group: group1, User: 1\n",
      "Group: group1, User: 28\n",
      "Group: group1, User: 37\n",
      "Group: group2, User: 11\n",
      "Group: group2, User: 20\n",
      "Group: group2, User: 29\n",
      "Group: group2, User: 2\n",
      "Group: group2, User: 38\n",
      "Group: group3, User: 12\n",
      "Group: group3, User: 21\n",
      "Group: group3, User: 30\n",
      "Group: group3, User: 39\n",
      "Group: group3, User: 3\n",
      "Group: group4, User: 13\n",
      "Group: group4, User: 22\n",
      "Group: group4, User: 31\n",
      "Group: group4, User: 40\n",
      "Group: group4, User: 4\n",
      "Group: group5, User: 14\n",
      "Group: group5, User: 23\n",
      "Group: group5, User: 32\n",
      "Group: group5, User: 41\n",
      "Group: group5, User: 5\n",
      "Group: group6, User: 15\n",
      "Group: group6, User: 24\n",
      "Group: group6, User: 33\n",
      "Group: group6, User: 42\n",
      "Group: group6, User: 6\n",
      "Group: group7, User: 16\n",
      "Group: group7, User: 25\n",
      "Group: group7, User: 34\n",
      "Group: group7, User: 43\n",
      "Group: group7, User: 7\n",
      "Group: group8, User: 17\n",
      "Group: group8, User: 26\n",
      "Group: group8, User: 35\n",
      "Group: group8, User: 44\n",
      "Group: group8, User: 8\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "cleaned_data = {}\n",
    "\n",
    "\n",
    "for group, users in groups_dfs.items():\n",
    "\n",
    "    cleaned_data[group] = {}\n",
    "\n",
    "    for user_id, df in users.items():\n",
    "\n",
    "        df['len_hr_time_series'] = df['hr_time_series'].apply(lambda x: len(ast.literal_eval(x)) if pd.notna(x) else 0)\n",
    "        df['len_resp_time_series'] = df['resp_time_series'].apply(lambda x: len(ast.literal_eval(x)) if pd.notna(x) else 0)\n",
    "        df['len_stress_time_series'] = df['stress_time_series'].apply(lambda x: len(ast.literal_eval(x)) if pd.notna(x) else 0)\n",
    "\n",
    "        coverage_hr_list=[]\n",
    "        coverage_resp_list=[]\n",
    "        coverage_stress_list=[]\n",
    "\n",
    "        for n in range(len(df)):\n",
    "            len_hr=df.iloc[n]['len_hr_time_series']\n",
    "            len_resp=df.iloc[n]['len_resp_time_series']\n",
    "            len_stress=df.iloc[n]['len_stress_time_series']\n",
    "\n",
    "\n",
    "            '''\n",
    "                in the hr-time_series the invald values are None \n",
    "                in the resp-time_series the invald values are -1/ -2\n",
    "                in the stress-time_series the invald values are -1/ -2\n",
    "\n",
    "            '''\n",
    "\n",
    "\n",
    "            len_valid_hr=0\n",
    "            len_valid_resp=0\n",
    "            len_valid_stress=0\n",
    "            hr_series=ast.literal_eval(df.iloc[n]['hr_time_series']) if pd.notna(df.iloc[n]['hr_time_series']) else []\n",
    "            resp_series=ast.literal_eval(df.iloc[n]['resp_time_series']) if pd.notna(df.iloc[n]['resp_time_series']) else []\n",
    "            stress_series=ast.literal_eval(df.iloc[n]['stress_time_series']) if pd.notna(df.iloc[n]['stress_time_series']) else []  \n",
    "            for i in range(len_hr):\n",
    "                if hr_series[i] is not None:\n",
    "                    len_valid_hr+=1\n",
    "            for i in range(len_resp):\n",
    "                if resp_series[i]!=-1 and resp_series[i]!=-2:\n",
    "                    len_valid_resp+=1\n",
    "            for i in range(len_stress):\n",
    "                if stress_series[i]!=-1 and stress_series[i]!=-2:\n",
    "                    len_valid_stress+=1\n",
    "            coverage_hr=len_valid_hr/len_hr if len_hr>0 else 0\n",
    "            coverage_resp=len_valid_resp/len_resp if len_resp>0 else 0\n",
    "            coverage_stress=len_valid_stress/len_stress if len_stress>0 else 0\n",
    "            coverage_hr_list.append(coverage_hr)\n",
    "            coverage_resp_list.append(coverage_resp)\n",
    "            coverage_stress_list.append(coverage_stress)\n",
    "            # print(f'Row {n}: coverage_hr={coverage_hr}, coverage_resp={coverage_resp}, coverage_stress={coverage_stress}')\n",
    "            # print(f'len_hr={len_hr}, len_resp={len_resp}, len_stress={len_stress}')\n",
    "            # print('--------------------------------------------')\n",
    "\n",
    "\n",
    "        df['coverage_hr']=coverage_hr_list\n",
    "        df['coverage_resp']=coverage_resp_list\n",
    "        df['coverage_stress']=coverage_stress_list\n",
    "\n",
    "\n",
    "        MIN_COVERAGE=0.75\n",
    "        #take only the rows where coverage_hr, coverage_resp, coverage_stress are all > MIN_COVERAGE\n",
    "        df_cleaned = df[(df['coverage_hr'] >= MIN_COVERAGE) &\n",
    "                        (df['coverage_resp'] >= MIN_COVERAGE) &\n",
    "                        (df['coverage_stress'] >= MIN_COVERAGE)]    \n",
    "        cleaned_data[group][user_id] = df_cleaned\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e3db3d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: group0, User: 0, Original Rows: 27, Cleaned Rows: 19, Removed: 8\n",
      "Group: group0, User: 18, Original Rows: 25, Cleaned Rows: 0, Removed: 25\n",
      "Group: group0, User: 27, Original Rows: 4, Cleaned Rows: 2, Removed: 2\n",
      "Group: group0, User: 36, Original Rows: 22, Cleaned Rows: 3, Removed: 19\n",
      "Group: group0, User: 9, Original Rows: 29, Cleaned Rows: 17, Removed: 12\n",
      "Group: group1, User: 10, Original Rows: 26, Cleaned Rows: 8, Removed: 18\n",
      "Group: group1, User: 19, Original Rows: 13, Cleaned Rows: 4, Removed: 9\n",
      "Group: group1, User: 1, Original Rows: 22, Cleaned Rows: 19, Removed: 3\n",
      "Group: group1, User: 28, Original Rows: 9, Cleaned Rows: 9, Removed: 0\n",
      "Group: group1, User: 37, Original Rows: 24, Cleaned Rows: 15, Removed: 9\n",
      "Group: group2, User: 11, Original Rows: 20, Cleaned Rows: 10, Removed: 10\n",
      "Group: group2, User: 20, Original Rows: 13, Cleaned Rows: 5, Removed: 8\n",
      "Group: group2, User: 29, Original Rows: 25, Cleaned Rows: 20, Removed: 5\n",
      "Group: group2, User: 2, Original Rows: 14, Cleaned Rows: 7, Removed: 7\n",
      "Group: group2, User: 38, Original Rows: 26, Cleaned Rows: 9, Removed: 17\n",
      "Group: group3, User: 12, Original Rows: 27, Cleaned Rows: 19, Removed: 8\n",
      "Group: group3, User: 21, Original Rows: 29, Cleaned Rows: 24, Removed: 5\n",
      "Group: group3, User: 30, Original Rows: 29, Cleaned Rows: 24, Removed: 5\n",
      "Group: group3, User: 39, Original Rows: 22, Cleaned Rows: 13, Removed: 9\n",
      "Group: group3, User: 3, Original Rows: 9, Cleaned Rows: 1, Removed: 8\n",
      "Group: group4, User: 13, Original Rows: 13, Cleaned Rows: 10, Removed: 3\n",
      "Group: group4, User: 22, Original Rows: 17, Cleaned Rows: 14, Removed: 3\n",
      "Group: group4, User: 31, Original Rows: 17, Cleaned Rows: 13, Removed: 4\n",
      "Group: group4, User: 40, Original Rows: 24, Cleaned Rows: 20, Removed: 4\n",
      "Group: group4, User: 4, Original Rows: 21, Cleaned Rows: 8, Removed: 13\n",
      "Group: group5, User: 14, Original Rows: 12, Cleaned Rows: 6, Removed: 6\n",
      "Group: group5, User: 23, Original Rows: 29, Cleaned Rows: 23, Removed: 6\n",
      "Group: group5, User: 32, Original Rows: 30, Cleaned Rows: 25, Removed: 5\n",
      "Group: group5, User: 41, Original Rows: 26, Cleaned Rows: 15, Removed: 11\n",
      "Group: group5, User: 5, Original Rows: 28, Cleaned Rows: 20, Removed: 8\n",
      "Group: group6, User: 15, Original Rows: 29, Cleaned Rows: 21, Removed: 8\n",
      "Group: group6, User: 24, Original Rows: 27, Cleaned Rows: 3, Removed: 24\n",
      "Group: group6, User: 33, Original Rows: 13, Cleaned Rows: 7, Removed: 6\n",
      "Group: group6, User: 42, Original Rows: 30, Cleaned Rows: 15, Removed: 15\n",
      "Group: group6, User: 6, Original Rows: 8, Cleaned Rows: 2, Removed: 6\n",
      "Group: group7, User: 16, Original Rows: 25, Cleaned Rows: 18, Removed: 7\n",
      "Group: group7, User: 25, Original Rows: 30, Cleaned Rows: 2, Removed: 28\n",
      "Group: group7, User: 34, Original Rows: 27, Cleaned Rows: 14, Removed: 13\n",
      "Group: group7, User: 43, Original Rows: 30, Cleaned Rows: 6, Removed: 24\n",
      "Group: group7, User: 7, Original Rows: 26, Cleaned Rows: 8, Removed: 18\n",
      "Group: group8, User: 17, Original Rows: 25, Cleaned Rows: 7, Removed: 18\n",
      "Group: group8, User: 26, Original Rows: 25, Cleaned Rows: 7, Removed: 18\n",
      "Group: group8, User: 35, Original Rows: 15, Cleaned Rows: 4, Removed: 11\n",
      "Group: group8, User: 44, Original Rows: 30, Cleaned Rows: 25, Removed: 5\n",
      "Group: group8, User: 8, Original Rows: 27, Cleaned Rows: 19, Removed: 8\n"
     ]
    }
   ],
   "source": [
    "# compare the difference in number of rows before and after cleaning\n",
    "for group, users in groups_dfs.items():\n",
    "    \n",
    "    for user_id, df in users.items():\n",
    "        df_clean = cleaned_data[group][user_id]\n",
    "        original_rows = len(df)\n",
    "        cleaned_rows = len(df_clean)\n",
    "        print(f'Group: {group}, User: {user_id}, Original Rows: {original_rows}, Cleaned Rows: {cleaned_rows}, Removed: {original_rows - cleaned_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d132782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_DIR = \"filtered_data\"\n",
    "\n",
    "# cartella principale\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "for group, users in cleaned_data.items():\n",
    "    group_dir = os.path.join(BASE_DIR, str(group))\n",
    "    os.makedirs(group_dir, exist_ok=True)\n",
    "\n",
    "    for user_id, df in users.items():\n",
    "        if df.empty:\n",
    "            continue  # opzionale: salta utenti senza row valide\n",
    "\n",
    "        file_path = os.path.join(group_dir, f\"dataset_user_{user_id}_train.csv\")\n",
    "        df.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
